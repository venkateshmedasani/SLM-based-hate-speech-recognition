Download and set up ollama and run ollama serve in terminal first for the llama model (install llama through ollama)
